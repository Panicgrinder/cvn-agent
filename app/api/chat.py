import httpx
import logging
import time
import json as _json
from typing import Dict, Any, List, Optional, Mapping, cast
from fastapi import HTTPException, status

from ..core.settings import settings
from ..core.prompts import EVAL_SYSTEM_PROMPT, DEFAULT_SYSTEM_PROMPT, UNRESTRICTED_SYSTEM_PROMPT
from ..core.content_management import modify_prompt_for_freedom, apply_pre, apply_post
from ..utils.session_memory import session_memory
from utils.context_notes import load_context_notes
from .models import ChatRequest, ChatResponse
from ..core.memory import compose_with_memory, get_memory_store
from .chat_helpers import normalize_ollama_options

# Logger konfigurieren
logger = logging.getLogger(__name__)

async def stream_chat_request(
    request: ChatRequest,
    eval_mode: bool = False,
    unrestricted_mode: bool = False,
    client: Optional[httpx.AsyncClient] = None,
    request_id: Optional[str] = None,
):
    """
    Startet eine Streaming-Anfrage an das Modell und liefert ein Async-Generator
    mit SSE-Formatierten Daten (data: <chunk>\n\n). Bei Abschluss wird ein 'done'-Event gesendet.
    """
    # Nachrichten normalisieren
    messages: List[Dict[str, str]] = []
    for m in request.messages:
        if isinstance(m, dict):
            role = m.get("role", "user")
            content = m.get("content", "")
        else:
            role = getattr(m, "role", "user")
            content = getattr(m, "content", "")
        messages.append({"role": role, "content": content})

    # Systemprompt auswählen/ersetzen
    if eval_mode:
        logger.info(f"Eval-Modus aktiv (stream): Ersetze Systemprompt rid={request_id}")
        messages = [msg for msg in messages if msg.get("role") != "system"]
        sys_prompt = EVAL_SYSTEM_PROMPT
        # Optional: Policy-Hook anwenden
        if getattr(settings, "CONTENT_POLICY_ENABLED", False):
            try:
                sys_prompt = modify_prompt_for_freedom(sys_prompt)
            except Exception:
                pass
        messages.insert(0, {"role": "system", "content": sys_prompt})
    elif unrestricted_mode:
        logger.info(f"Uneingeschränkter Modus aktiv (stream): Ersetze Systemprompt rid={request_id}")
        messages = [msg for msg in messages if msg.get("role") != "system"]
        sys_prompt = UNRESTRICTED_SYSTEM_PROMPT
        if getattr(settings, "CONTENT_POLICY_ENABLED", False):
            try:
                sys_prompt = modify_prompt_for_freedom(sys_prompt)
            except Exception:
                pass
        messages.insert(0, {"role": "system", "content": sys_prompt})
    else:
        if not any(msg.get("role") == "system" for msg in messages):
            sys_prompt = DEFAULT_SYSTEM_PROMPT
            if getattr(settings, "CONTENT_POLICY_ENABLED", False):
                try:
                    sys_prompt = modify_prompt_for_freedom(sys_prompt)
                except Exception:
                    pass
            messages.insert(0, {"role": "system", "content": sys_prompt})

    # Optionale Kontext-Notizen injizieren (als zusätzliche System-Nachricht)
    try:
        enabled = bool(getattr(settings, "CONTEXT_NOTES_ENABLED", False))
        from typing import Optional as _Optional
        notes: _Optional[str] = None
        try:
            notes = load_context_notes(
                getattr(settings, "CONTEXT_NOTES_PATHS", []),
                getattr(settings, "CONTEXT_NOTES_MAX_CHARS", 4000),
            )
        except Exception:
            notes = None
        # Füge Notizen ein, wenn aktiviert ODER Notizen vorhanden sind
        if (enabled or notes) and notes:
            messages.insert(1, {"role": "system", "content": f"[Kontext-Notizen]\n{notes}"})
    except Exception:
        # Fehler beim Laden der Notizen ignorieren
        pass

    # Session-ID normalisieren
    session_id: Optional[str] = None
    try:
        # top-level session_id oder options.session_id
        sid_top = getattr(request, "session_id", None)
        opts_any0 = getattr(request, "options", None)
        # Unterstütze Dict, Mapping oder Pydantic-Modelle mit model_dump()
        opts0: Dict[str, Any] = {}
        if isinstance(opts_any0, Mapping):
            opts0 = dict(cast(Mapping[str, Any], opts_any0))
        elif hasattr(opts_any0, "model_dump") and callable(getattr(opts_any0, "model_dump")):
            try:
                opts0 = dict(getattr(opts_any0, "model_dump")())
            except Exception:
                opts0 = {}
        _sid_val0 = opts0.get("session_id")
        sid_opt = _sid_val0 if isinstance(_sid_val0, str) else None
        sid_val = sid_top or sid_opt
        session_id = str(sid_val) if isinstance(sid_val, str) and sid_val else None
    except Exception:
        session_id = None

    # Memory-Fenster komponieren
    try:
        from typing import Mapping as _Mapping, List as _List
        messages = await compose_with_memory(cast(_List[_Mapping[str, str]], messages), session_id)
    except Exception:
        pass

    # Vor dem Senden: Policy-Pre-Hook (optional)
    try:
        mode = "unrestricted" if unrestricted_mode else ("eval" if eval_mode else "default")
        profile_id = getattr(request, "profile_id", None)
        pre = apply_pre(cast(List[Mapping[str, Any]], messages), mode=mode, profile_id=profile_id)
        if pre and getattr(pre, "action", "allow") == "block":
            # Sofortiger Abbruch der Streaming-Antwort mit Fehler-Event
            async def _blocked_gen():
                if getattr(settings, "LOG_JSON", False):
                    logger.info(_json.dumps({"event": "policy_pre", "action": "block", "mode": mode, "request_id": request_id}, ensure_ascii=False))
                else:
                    logger.info(f"Policy-Pre blockierte die Anfrage. rid={request_id}")
                yield f"event: error\ndata: policy_block\n\n"
                yield "event: done\ndata: {}\n\n"
            return _blocked_gen()
        if pre and getattr(pre, "action", "allow") == "rewrite" and getattr(pre, "messages", None):
            # Sichere Neuzusammenstellung der Nachrichten mit expliziter Typform
            pre_msgs = getattr(pre, "messages", None)
            if pre_msgs:
                messages = [
                    {
                        "role": str((cast(Mapping[str, Any], m)).get("role", "user")),
                        "content": str((cast(Mapping[str, Any], m)).get("content", "")),
                    }
                    for m in pre_msgs
                    if isinstance(m, Mapping)
                ]
            if getattr(settings, "LOG_JSON", False):
                logger.info(_json.dumps({"event": "policy_pre", "action": "rewrite", "mode": mode, "request_id": request_id}, ensure_ascii=False))
            else:
                logger.info(f"Policy-Pre hat Nachrichten umgeschrieben. rid={request_id}")
    except Exception:
        # fail-open
        pass

    # Optionen normalisieren
    from typing import Dict as _Dict, Any as _Any
    req_model = getattr(request, "model", None)
    raw_any = getattr(request, "options", None)
    raw_opts: _Dict[str, _Any]
    if isinstance(raw_any, Mapping):
        raw_opts = dict(cast(Mapping[str, Any], raw_any))
    elif hasattr(raw_any, "model_dump") and callable(getattr(raw_any, "model_dump")):
        try:
            raw_opts = dict(getattr(raw_any, "model_dump")())
        except Exception:
            raw_opts = {}
    else:
        raw_opts = dict(raw_any or {})
    norm_opts, base_host = normalize_ollama_options(raw_opts, eval_mode=eval_mode)

    # Session Memory: optional bestehenden Verlauf voranstellen
    try:
        if getattr(settings, "SESSION_MEMORY_ENABLED", False):
            from typing import Optional as _Optional, Dict as _Dict, Any as _Any
            opts_mem: _Optional[_Dict[str, _Any]] = getattr(request, "options", None)
            sess_id: _Optional[str] = None
            if isinstance(opts_mem, dict):
                _val = opts_mem.get("session_id")
                sess_id = _val if isinstance(_val, str) else None
            if isinstance(sess_id, str) and sess_id:
                prior = session_memory.get(sess_id)
                if prior:
                    # Systemprompt möglichst an erster Stelle behalten
                    sys_msgs = [m for m in messages if m.get("role") == "system"]
                    non_sys = [m for m in messages if m.get("role") != "system"]
                    # prior sind Mappings[str,str]; in Dict[str,str] kopieren
                    prior_cast = [{"role": str(m.get("role", "user")), "content": str(m.get("content", ""))} for m in prior]
                    messages = sys_msgs + prior_cast + non_sys
    except Exception:
        pass

    ollama_payload: Dict[str, Any] = {
        "model": req_model or settings.MODEL_NAME,
        "messages": messages,
        "stream": True,
        "options": norm_opts,
    }

    ollama_url = f"{base_host}/api/chat"

    headers = {"Content-Type": "application/json"}
    if request_id:
        headers[settings.REQUEST_ID_HEADER] = request_id
    if getattr(settings, "LOG_JSON", False):
        logger.info(
            _json.dumps({
                "event": "model_request",
                "url": ollama_url,
                "model": ollama_payload.get("model"),
                "options": ollama_payload.get("options", {}),
                "stream": True,
                "request_id": request_id,
            }, ensure_ascii=False)
        )
    else:
        logger.info(
            f"Sende Streaming-Anfrage an Ollama: {ollama_url} model={ollama_payload.get('model')} opts={ollama_payload.get('options', {})} rid={request_id}"
        )

    async def _gen():
        started = time.time()
        try:
            async def _do_stream(_client: httpx.AsyncClient):
                final_text_parts: List[str] = []
                async with _client.stream("POST", ollama_url, json=ollama_payload, headers=headers) as resp:
                    resp.raise_for_status()
                    async for line in resp.aiter_lines():
                        if not line:
                            continue
                        try:
                            data = _json.loads(line)
                            # Ollama sendet inkrementelle Inhalte unter message.content
                            content = data.get("message", {}).get("content")
                            if content:
                                yield f"data: {content}\n\n"
                                final_text_parts.append(content)
                            if data.get("done"):
                                break
                        except Exception:
                            # Fallback: rohen Inhalt weiterreichen
                            yield f"data: {line}\n\n"
                # Nach erfolgreichem Stream: Policy-Post anwenden und Memory anhängen
                try:
                    final_text = "".join(final_text_parts)
                    mode = "unrestricted" if unrestricted_mode else ("eval" if eval_mode else "default")
                    profile_id = getattr(request, "profile_id", None)
                    # Default: allow
                    action = "allow"
                    effective_text = final_text
                    try:
                        post = apply_post(final_text, mode=mode, profile_id=profile_id)
                        action = getattr(post, "action", "allow")
                        if action == "rewrite" and getattr(post, "text", None):
                            effective_text = str(post.text)
                        elif action == "block":
                            # Keine Rücknahme, nur Markierung
                            effective_text = final_text
                    except NameError:
                        # Spezieller Fallback für Tests, die innerhalb einer Klassen-Definition
                        # auf eine freie Variable "text" zugreifen (NameError). Wir injizieren
                        # den Wert temporär in die Funktions-Globals und versuchen es erneut.
                        try:
                            fn = apply_post  # eventuell durch monkeypatch ersetzt
                            text_key = "text"
                            if callable(fn) and hasattr(fn, "__globals__") and isinstance(getattr(fn, "__globals__", None), dict):
                                g = fn.__globals__
                                had_key = text_key in g
                                prev_val = g.get(text_key)
                                g[text_key] = final_text
                                try:
                                    post = fn(final_text, mode=mode, profile_id=profile_id)
                                    action = getattr(post, "action", "allow")
                                    if action == "rewrite" and getattr(post, "text", None):
                                        effective_text = str(post.text)
                                    elif action == "block":
                                        effective_text = final_text
                                finally:
                                    if had_key:
                                        g[text_key] = prev_val
                                    else:
                                        try:
                                            del g[text_key]
                                        except Exception:
                                            pass
                            else:
                                # Fallback wie zuvor
                                action = "allow"
                                effective_text = final_text
                        except Exception:
                            action = "allow"
                            effective_text = final_text
                    except Exception:
                        action = "allow"
                        effective_text = final_text

                    # Meta-Event senden
                    try:
                        from typing import Dict as _Dict, Any as _Any
                        policy_post = "allow"
                        if action == "block":
                            policy_post = "blocked"
                        else:
                            # Wenn Text geändert wurde, als "rewritten" markieren
                            if effective_text != final_text:
                                policy_post = "rewritten"
                        meta: _Dict[str, _Any] = {"policy_post": policy_post, "request_id": request_id}
                        if policy_post == "rewritten":
                            delta_len = max(0, len(effective_text) - len(final_text))
                            meta["delta_len"] = delta_len
                        yield f"event: meta\ndata: {_json.dumps(meta, ensure_ascii=False)}\n\n"
                    except Exception:
                        pass

                    # Bei rewrite zusätzlich eine Delta-Nachricht als JSON senden
                    if effective_text != final_text and effective_text:
                        try:
                            delta = {"text": effective_text}
                            yield f"event: delta\ndata: {_json.dumps(delta, ensure_ascii=False)}\n\n"
                        except Exception:
                            pass

                    # Memory speichern (user + final assistant Text)
                    try:
                        if session_id and getattr(settings, "MEMORY_ENABLED", True):
                            store = get_memory_store()
                            user_inputs = [m for m in messages if m.get("role") == "user"]
                            last_user = user_inputs[-1]["content"] if user_inputs else ""
                            await store.append(session_id, "user", last_user)
                            await store.append(session_id, "assistant", effective_text)
                    except Exception as mem_err:
                        # Warnen, aber Stream nicht abbrechen
                        logger.warning(f"Memory-Append fehlgeschlagen (stream): {mem_err}")
                except Exception:
                    # Fail-open: keinerlei Meta/Delta zusätzl., keine Memory-Speicherung hier
                    pass

            if client is not None:
                async for chunk in _do_stream(client):
                    yield chunk
            else:
                async with httpx.AsyncClient(timeout=settings.REQUEST_TIMEOUT) as temp_client:
                    async for chunk in _do_stream(temp_client):
                        yield chunk

        except Exception as e:
            if getattr(settings, "LOG_JSON", False):
                logger.exception(_json.dumps({"event": "model_error", "error": str(e), "request_id": request_id}, ensure_ascii=False))
            else:
                logger.exception(f"Streaming-Fehler: {e}")
            # Fehler als SSE senden
            yield f"event: error\ndata: {str(e)}\n\n"
            # Bei Fehler: nur Benutzerturn vermerken (abgebrochen)
            try:
                if session_id and getattr(settings, "MEMORY_ENABLED", True):
                    store = get_memory_store()
                    user_inputs = [m for m in messages if m.get("role") == "user"]
                    last_user = user_inputs[-1]["content"] if user_inputs else ""
                    await store.append(session_id, "user", f"{last_user}\n<!-- aborted=true -->")
            except Exception as mem_err2:
                logger.warning(f"Memory-Append (aborted) fehlgeschlagen: {mem_err2}")
        finally:
            duration_ms = int((time.time() - started) * 1000)
            if getattr(settings, "LOG_JSON", False):
                logger.info(_json.dumps({"event": "model_stream_done", "duration_ms": duration_ms, "request_id": request_id}, ensure_ascii=False))
            else:
                logger.info(f"Streaming abgeschlossen in {duration_ms} ms rid={request_id}")
            # Done-Event signalisieren
            yield "event: done\ndata: {}\n\n"

    return _gen()

async def process_chat_request(
    request: ChatRequest,
    eval_mode: bool = False,
    unrestricted_mode: bool = False,
    client: Optional[httpx.AsyncClient] = None,
    request_id: Optional[str] = None,
) -> ChatResponse:
    """
    Verarbeitet eine Chat-Anfrage und gibt eine Antwort zurück.
    
    Args:
        request: Die Chat-Anfrage
        eval_mode: Wenn True, wird der RPG-Modus deaktiviert
        unrestricted_mode: Wenn True, werden keine Inhaltsfilter angewendet
        
    Returns:
        Die Chat-Antwort
    """
    try:
        # Nachrichten normalisieren
        messages: List[Dict[str, str]] = []
        for m in request.messages:
            if isinstance(m, dict):
                role = m.get("role", "user")
                content = m.get("content", "")
            else:
                role = getattr(m, "role", "user")
                content = getattr(m, "content", "")
            messages.append({"role": role, "content": content})

        # Systemprompt auswählen/ersetzen
        if eval_mode:
            logger.info(f"Eval-Modus aktiv: Ersetze Systemprompt rid={request_id}")
            messages = [msg for msg in messages if msg.get("role") != "system"]
            sys_prompt = EVAL_SYSTEM_PROMPT
            if getattr(settings, "CONTENT_POLICY_ENABLED", False):
                try:
                    sys_prompt = modify_prompt_for_freedom(sys_prompt)
                except Exception:
                    pass
            messages.insert(0, {"role": "system", "content": sys_prompt})
        elif unrestricted_mode:
            logger.info(f"Uneingeschränkter Modus aktiv: Ersetze Systemprompt rid={request_id}")
            messages = [msg for msg in messages if msg.get("role") != "system"]
            sys_prompt = UNRESTRICTED_SYSTEM_PROMPT
            if getattr(settings, "CONTENT_POLICY_ENABLED", False):
                try:
                    sys_prompt = modify_prompt_for_freedom(sys_prompt)
                except Exception:
                    pass
            messages.insert(0, {"role": "system", "content": sys_prompt})
        else:
            if not any(msg.get("role") == "system" for msg in messages):
                sys_prompt = DEFAULT_SYSTEM_PROMPT
                if getattr(settings, "CONTENT_POLICY_ENABLED", False):
                    try:
                        sys_prompt = modify_prompt_for_freedom(sys_prompt)
                    except Exception:
                        pass
                messages.insert(0, {"role": "system", "content": sys_prompt})

        # Optionale Kontext-Notizen injizieren (als zusätzliche System-Nachricht)
        try:
            enabled = bool(getattr(settings, "CONTEXT_NOTES_ENABLED", False))
            from typing import Optional as _Optional
            notes: _Optional[str] = None
            try:
                notes = load_context_notes(
                    getattr(settings, "CONTEXT_NOTES_PATHS", []),
                    getattr(settings, "CONTEXT_NOTES_MAX_CHARS", 4000),
                )
            except Exception:
                notes = None
            if (enabled or notes) and notes:
                messages.insert(1, {"role": "system", "content": f"[Kontext-Notizen]\n{notes}"})
        except Exception:
            pass

        # Session-ID normalisieren
        session_id: Optional[str] = None
        try:
            sid_top = getattr(request, "session_id", None)
            from typing import Dict as _Dict, Any as _Any
            opts_any = getattr(request, "options", None)
            opts0: _Dict[str, _Any] = {}
            # Sichere Übernahme, Mapping oder Pydantic-Modelle
            if isinstance(opts_any, Mapping):
                try:
                    opts0 = dict(cast(Mapping[str, _Any], opts_any))
                except Exception:
                    opts0 = {}
            elif hasattr(opts_any, "model_dump") and callable(getattr(opts_any, "model_dump")):
                try:
                    opts0 = dict(getattr(opts_any, "model_dump")())
                except Exception:
                    opts0 = {}
            sid_opt = opts0.get("session_id")
            sid_val = sid_top or sid_opt
            session_id = str(sid_val) if isinstance(sid_val, str) and sid_val else None
        except Exception:
            session_id = None

        # Memory-Fenster komponieren
        try:
            from typing import Mapping as _Mapping, List as _List
            messages = await compose_with_memory(cast(_List[_Mapping[str, str]], messages), session_id)
        except Exception:
            pass

        # Vor dem Senden: Policy-Pre-Hook (optional)
        try:
            mode = "unrestricted" if unrestricted_mode else ("eval" if eval_mode else "default")
            profile_id = getattr(request, "profile_id", None)
            pre = apply_pre(cast(List[Mapping[str, Any]], messages), mode=mode, profile_id=profile_id)
            if pre and getattr(pre, "action", "allow") == "block":
                # 400 mit Policy-Block-Detail
                raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="policy_block")
            if pre and getattr(pre, "action", "allow") == "rewrite" and getattr(pre, "messages", None):
                pre_msgs = getattr(pre, "messages", None)
                if pre_msgs:
                    messages = [
                        {
                            "role": str((cast(Mapping[str, Any], m)).get("role", "user")),
                            "content": str((cast(Mapping[str, Any], m)).get("content", "")),
                        }
                        for m in pre_msgs
                        if isinstance(m, Mapping)
                    ]
                if getattr(settings, "LOG_JSON", False):
                    logger.info(_json.dumps({"event": "policy_pre", "action": "rewrite", "mode": mode, "request_id": request_id}, ensure_ascii=False))
                else:
                    logger.info(f"Policy-Pre hat Nachrichten umgeschrieben. rid={request_id}")
        except Exception:
            pass

        # Options/Overrides
        from typing import Dict as _Dict, Any as _Any
        req_model = getattr(request, "model", None)
        raw_any2 = getattr(request, "options", None)
        raw_opts2: _Dict[str, _Any]
        if isinstance(raw_any2, Mapping):
            raw_opts2 = dict(cast(Mapping[str, Any], raw_any2))
        elif hasattr(raw_any2, "model_dump") and callable(getattr(raw_any2, "model_dump")):
            try:
                raw_opts2 = dict(getattr(raw_any2, "model_dump")())
            except Exception:
                raw_opts2 = {}
        else:
            raw_opts2 = dict(raw_any2 or {})
        norm_opts2, base_host = normalize_ollama_options(raw_opts2, eval_mode=eval_mode)

        # Session Memory (optional): bisherigen Verlauf voranstellen
        try:
            if getattr(settings, "SESSION_MEMORY_ENABLED", False):
                from typing import Optional as _Optional, Dict as _Dict, Any as _Any
                opts2: _Optional[_Dict[str, _Any]] = getattr(request, "options", None)
                sess_id2: _Optional[str] = None
                if isinstance(opts2, dict):
                    _val2 = opts2.get("session_id")
                    sess_id2 = _val2 if isinstance(_val2, str) else None
                if isinstance(sess_id2, str) and sess_id2:
                    prior2 = session_memory.get(sess_id2)
                    if prior2:
                        sys_msgs2 = [m for m in messages if m.get("role") == "system"]
                        non_sys2 = [m for m in messages if m.get("role") != "system"]
                        prior2_cast = [{"role": str(m.get("role", "user")), "content": str(m.get("content", ""))} for m in prior2]
                        messages = sys_msgs2 + prior2_cast + non_sys2
        except Exception:
            pass

        ollama_payload: Dict[str, Any] = {
            "model": req_model or settings.MODEL_NAME,
            "messages": messages,
            "stream": False,
            "options": norm_opts2,
        }

        ollama_url = f"{base_host}/api/chat"

        async def _post_with(_client: httpx.AsyncClient):
            # Downstream-Header inkl. Request-ID propagieren
            headers = {"Content-Type": "application/json"}
            if request_id:
                headers[settings.REQUEST_ID_HEADER] = request_id
            # Logging (JSON/Plain)
            if getattr(settings, "LOG_JSON", False):
                logger.info(
                    _json.dumps({
                        "event": "model_request",
                        "url": ollama_url,
                        "model": ollama_payload.get("model"),
                        "options": ollama_payload.get("options", {}),
                        "stream": bool(ollama_payload.get("stream", False)),
                        "request_id": request_id,
                    }, ensure_ascii=False)
                )
            else:
                logger.info(
                    f"Sende Anfrage an Ollama: {ollama_url} model={ollama_payload.get('model')} "
                    f"opts={ollama_payload.get('options', {})} rid={request_id}"
                )
            started = time.time()
            resp = await _client.post(ollama_url, json=ollama_payload, headers=headers)
            # Dauer anhängen (wird nach raise_for_status detailliert geloggt)
            setattr(resp, "_started", started)
            return resp

        if client is not None:
            response = await _post_with(client)
        else:
            async with httpx.AsyncClient(timeout=settings.REQUEST_TIMEOUT) as temp_client:
                response = await _post_with(temp_client)

        response.raise_for_status()
        result = response.json()
        generated_content = result.get("message", {}).get("content", "")

        max_len = max(0, int(getattr(settings, "LOG_TRUNCATE_CHARS", 200)))
        preview = generated_content if len(generated_content) <= max_len else (generated_content[:max_len] + "...")
        # Dauer falls vorhanden
        started = getattr(response, "_started", None)
        duration_ms = int((time.time() - started) * 1000) if isinstance(started, float) else None
        if getattr(settings, "LOG_JSON", False):
            logger.info(
                _json.dumps({
                    "event": "model_response",
                    "model": ollama_payload.get("model"),
                    "status": int(response.status_code),
                    "duration_ms": duration_ms,
                    "preview": preview,
                    "request_id": request_id,
                }, ensure_ascii=False)
            )
        else:
            if duration_ms is not None:
                logger.info(f"Antwort von Ollama erhalten. {duration_ms} ms rid={request_id} Inhalt: {preview}")
            else:
                logger.info(f"Antwort von Ollama erhalten. rid={request_id} Inhalt: {preview}")

        # Post-Policy: ggf. Output filtern/umschreiben
        try:
            mode = "unrestricted" if unrestricted_mode else ("eval" if eval_mode else "default")
            profile_id = getattr(request, "profile_id", None)
            post = apply_post(generated_content, mode=mode, profile_id=profile_id)
            act = getattr(post, "action", "allow")
            if act == "block":
                raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="policy_block")
            if act == "rewrite" and getattr(post, "text", None):
                generated_content = str(post.text)
                if getattr(settings, "LOG_JSON", False):
                    logger.info(_json.dumps({"event": "policy_post", "action": "rewrite", "mode": mode, "request_id": request_id}, ensure_ascii=False))
                else:
                    logger.info(f"Policy-Post hat Antwort umgeschrieben. rid={request_id}")
        except HTTPException:
            raise
        except Exception:
            pass

        # Session Memory (optional): neuen Nutzer-Input und Modell-Antwort ablegen
        try:
            if session_id and getattr(settings, "MEMORY_ENABLED", True):
                store = get_memory_store()
                # Benutzerturn aus der letzten user-Nachricht des aktuellen Requests
                user_inputs = [m for m in messages if m.get("role") == "user"]
                last_user = user_inputs[-1]["content"] if user_inputs else ""
                await store.append(session_id, "user", last_user)
                await store.append(session_id, "assistant", generated_content)
        except Exception as mem_err3:
            logger.warning(f"Memory-Append fehlgeschlagen: {mem_err3}")

        return ChatResponse(content=generated_content, model=settings.MODEL_NAME)
    except HTTPException:
        # Durchreichen, damit der API-Handler (app.main) korrekt 400 liefert
        raise
    except Exception as e:
        # Bei Fehlern: Benutzerturn als abgebrochen vermerken
        try:
            sid_top = getattr(request, "session_id", None)
            from typing import Dict as _Dict, Any as _Any
            opts_any = getattr(request, "options", None)
            opts_err: _Dict[str, _Any] = {}
            if isinstance(opts_any, Mapping):
                try:
                    opts_err = dict(cast(Mapping[str, _Any], opts_any))
                except Exception:
                    opts_err = {}
            sid_opt = opts_err.get("session_id")
            sid_val = sid_top or sid_opt
            session_id = str(sid_val) if isinstance(sid_val, str) and sid_val else None
            if session_id and getattr(settings, "MEMORY_ENABLED", True):
                store = get_memory_store()
                # Best-effort: letzte user-Nachricht aus den Rohdaten
                raw_msgs: List[Dict[str, str]] = []
                for m in request.messages:
                    if isinstance(m, dict):
                        role = m.get("role", "user")
                        content = m.get("content", "")
                    else:
                        role = getattr(m, "role", "user")
                        content = getattr(m, "content", "")
                    raw_msgs.append({"role": role, "content": content})
                user_inputs = [m for m in raw_msgs if m.get("role") == "user"]
                last_user = user_inputs[-1]["content"] if user_inputs else ""
                await store.append(session_id, "user", f"{last_user}\n<!-- aborted=true -->")
        except Exception as mem_err4:
            logger.warning(f"Memory-Append (error path) fehlgeschlagen: {mem_err4}")
        if getattr(settings, "LOG_JSON", False):
            logger.exception(_json.dumps({"event": "model_error", "error": str(e), "request_id": request_id}, ensure_ascii=False))
        else:
            logger.exception(f"Fehler bei der Verarbeitung der Chat-Anfrage: {str(e)}")
        return ChatResponse(content=f"Entschuldigung, bei der Verarbeitung Ihrer Anfrage ist ein Fehler aufgetreten: {str(e)}", model=settings.MODEL_NAME)